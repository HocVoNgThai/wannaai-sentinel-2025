{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f03629-6c23-4ac8-9f96-c7d9ee5d5240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> BƯỚC 1: Cấu hình và Thiết lập <<<\n",
      "\n",
      ">>> BƯỚC 2: Tải và Xử lý Dữ liệu theo Chunk <<<\n",
      "Đang xử lý chunk 1...\n",
      "Đang xử lý chunk 2...\n",
      "Đang xử lý chunk 3...\n",
      "Đang xử lý chunk 4...\n",
      "Đang xử lý chunk 5...\n",
      "Ghép các chunk của train_df...\n",
      "\n",
      "Tổng bộ nhớ của train_df sau khi ghép: 3456.16 MB\n",
      "Ghép các chunk của test_df...\n",
      "\n",
      "Train shape: (22509617, 40)\n",
      "Test shape: (11241807, 39)\n",
      "\n",
      ">>> BƯỚC 3: Tiền xử lý Chung <<<\n",
      "Áp dụng biến đổi log1p...\n",
      "Encode Label...\n",
      "\n",
      ">>> BƯỚC 4: Chuẩn bị Dữ liệu cho Model <<<\n",
      "Train split: (20258655, 39), Valid split: (2250962, 39)\n",
      "\n",
      ">>> BƯỚC 5: Huấn luyện Model XGBoost <<<\n",
      "Bắt đầu training với Early Stopping...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 140\u001b[0m\n\u001b[1;32m    125\u001b[0m xgb_clf \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[1;32m    126\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(le\u001b[38;5;241m.\u001b[39mclasses_),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBắt đầu training với Early Stopping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m    145\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# --- 6. Đánh giá và Dự đoán ---\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>>> BƯỚC 6: Đánh giá và Dự đoán <<<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import gc # Thư viện Garbage Collection để giải phóng bộ nhớ\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Cấu hình và Hàm Tối ưu Bộ nhớ ---\n",
    "print(\">>> BƯỚC 1: Cấu hình và Thiết lập <<<\")\n",
    "\n",
    "TRAIN_PATH = 'wannaai-sentinel-2025/train.csv'\n",
    "TEST_PATH = 'wannaai-sentinel-2025/test.csv'\n",
    "CHUNK_SIZE = 5_000_000 # Đọc 5 triệu dòng mỗi lần, bạn có thể giảm xuống nếu vẫn bị lỗi\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object and col_type.name != 'category':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Mức sử dụng bộ nhớ giảm từ {start_mem:.2f} MB xuống {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% giảm)')\n",
    "    return df\n",
    "\n",
    "# --- 2. Tải Dữ liệu theo Chunk và Xử lý ---\n",
    "print(\"\\n>>> BƯỚC 2: Tải và Xử lý Dữ liệu theo Chunk <<<\")\n",
    "\n",
    "# Xử lý file train\n",
    "train_chunks = []\n",
    "# Sử dụng pd.read_csv với iterator và chunksize\n",
    "for chunk in pd.read_csv(TRAIN_PATH, chunksize=CHUNK_SIZE):\n",
    "    print(f\"Đang xử lý chunk {len(train_chunks) + 1}...\")\n",
    "    # 1. Làm sạch NaN/Inf\n",
    "    chunk.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    chunk.fillna(0, inplace=True)\n",
    "    \n",
    "    # 2. Tối ưu bộ nhớ cho chunk\n",
    "    chunk = reduce_mem_usage(chunk, verbose=False) # Tắt verbose để đỡ rối output\n",
    "    \n",
    "    train_chunks.append(chunk)\n",
    "\n",
    "print(\"Ghép các chunk của train_df...\")\n",
    "train_df = pd.concat(train_chunks, ignore_index=True)\n",
    "del train_chunks # Giải phóng bộ nhớ ngay lập tức\n",
    "gc.collect() # Dọn dẹp rác\n",
    "\n",
    "print(f\"\\nTổng bộ nhớ của train_df sau khi ghép: {train_df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Xử lý file test (tương tự)\n",
    "test_chunks = []\n",
    "for chunk in pd.read_csv(TEST_PATH, chunksize=CHUNK_SIZE):\n",
    "    chunk.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    chunk.fillna(0, inplace=True)\n",
    "    chunk = reduce_mem_usage(chunk, verbose=False)\n",
    "    test_chunks.append(chunk)\n",
    "    \n",
    "print(\"Ghép các chunk của test_df...\")\n",
    "test_df = pd.concat(test_chunks, ignore_index=True)\n",
    "del test_chunks\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "\n",
    "# --- 3. Tiền xử lý Chung ---\n",
    "print(\"\\n>>> BƯỚC 3: Tiền xử lý Chung <<<\")\n",
    "\n",
    "print(\"Áp dụng biến đổi log1p...\")\n",
    "problematic_features = [\"Rate\", \"Std length\", \"Variance length\"]\n",
    "for col in problematic_features:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = np.log1p(train_df[col].astype(np.float32))\n",
    "        test_df[col] = np.log1p(test_df[col].astype(np.float32))\n",
    "\n",
    "print(\"Encode Label...\")\n",
    "le = LabelEncoder()\n",
    "train_df[\"label_mapped\"] = le.fit_transform(train_df[\"Label\"])\n",
    "\n",
    "\n",
    "# --- 4. Chuẩn bị Dữ liệu để Huấn luyện ---\n",
    "print(\"\\n>>> BƯỚC 4: Chuẩn bị Dữ liệu cho Model <<<\")\n",
    "X = train_df.drop([\"Label\", \"label_mapped\"], axis=1)\n",
    "y = train_df[\"label_mapped\"]\n",
    "\n",
    "# Xóa train_df để giải phóng thêm RAM trước khi training\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Xóa X, y không cần thiết nữa\n",
    "del X, y\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Train split: {X_train.shape}, Valid split: {X_val.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2051c-84c2-4f80-87c7-02ea57259343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> BƯỚC 5: Huấn luyện Model XGBoost <<<\n",
      "Bắt đầu training với Early Stopping...\n",
      "[0]\tvalidation_0-mlogloss:2.94136\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Huấn luyện Model XGBoost ---\n",
    "print(\"\\n>>> BƯỚC 5: Huấn luyện Model XGBoost <<<\")\n",
    "\n",
    "# Giảm các tham số để tiết kiệm RAM hơn nữa\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(le.classes_),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,          # Giảm độ sâu của cây\n",
    "    subsample=0.7,        # Dùng ít dữ liệu hơn cho mỗi cây\n",
    "    colsample_bytree=0.7, # Dùng ít feature hơn cho mỗi cây\n",
    "    tree_method=\"hist\",   # 'hist' rất hiệu quả về bộ nhớ và tốc độ\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "print(\"Bắt đầu training với Early Stopping...\")\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    #early_stopping_rounds=30,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# --- 6. Đánh giá và Dự đoán ---\n",
    "print(\"\\n>>> BƯỚC 6: Đánh giá và Dự đoán <<<\")\n",
    "print(\"Đánh giá trên tập Validation...\")\n",
    "y_pred_val = xgb_clf.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
    "\n",
    "print(\"\\nDự đoán trên tập Test...\")\n",
    "test_pred_encoded = xgb_clf.predict(test_df)\n",
    "test_pred_labels = le.inverse_transform(test_pred_encoded)\n",
    "\n",
    "# --- 7. Tạo file Submission ---\n",
    "print(\"\\n>>> BƯỚC 7: Tạo file Submission <<<\")\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(test_pred_labels)),\n",
    "    \"Label\": test_pred_labels\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Hoàn tất! File 'submission.csv' đã được tạo.\")\n",
    "print(\"5 dòng đầu của file submission:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122a98e-ff39-4dee-a262-7a08b35fdf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
